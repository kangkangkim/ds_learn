{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Based Model Practice\n",
    "## Key Points\n",
    "### 1 - Decision Tree simple model example with Tree View, recursive partition algrithm visulization\n",
    "### 2 - Measure of Impurity\n",
    "### 3 - Bagging and Random Forest\n",
    "### 4 - Xgboost\n",
    "### 5 - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pydotplus\n",
    "from dmba import plotDecisionTree, textDecisionTree\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths to data sets. If you don't keep your data in the same directory as the code, adapt the path names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('.').resolve().parents[1] / 'Class3/treepractice'\n",
    "\n",
    "# print(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAN3000_CSV = DATA / 'loan3000.csv'\n",
    "LOAN_DATA_CSV = DATA / 'loan_data.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Models\n",
    "## A simple tree with visulization\n",
    "The package _scikit-learn_ has the class `DecisionTreeClassifier` to build a decision tree model. The function `plotDecisionTree` from the _dmba_ package can be used to visualize the tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit the tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan3000 = pd.read_csv(LOAN3000_CSV)\n",
    "\n",
    "predictors = ['borrower_score', 'payment_inc_ratio']\n",
    "outcome = 'outcome'\n",
    "\n",
    "X = loan3000[predictors]\n",
    "y = loan3000[outcome]\n",
    "\n",
    "loan_tree = DecisionTreeClassifier(random_state=1, criterion='entropy',\n",
    "                                   min_impurity_decrease=0.003)\n",
    "loan_tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use exisitng module from dmba package for visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDecisionTree(loan_tree, feature_names=predictors, class_names=loan_tree.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use SKlearn module and image to visulize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from IPython.display import Image \n",
    "# Create DOT data\n",
    "dot_data = tree.export_graphviz(loan_tree, out_file=None, \n",
    "                                feature_names=predictors,  \n",
    "                                class_names=loan_tree.classes_)\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Recursive Partitioning Algorithm and Tree example display the Algorithm\n",
    "The data is repeatedly partitioned using predictor values which could do the best job of separating the data into relatively homogeneous partitions respect to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "loan3000.loc[loan3000.outcome=='paid off'].plot(\n",
    "    x='borrower_score', y='payment_inc_ratio', style='.', \n",
    "    markerfacecolor='none', markeredgecolor='C1', ax=ax)\n",
    "loan3000.loc[loan3000.outcome=='default'].plot(\n",
    "    x='borrower_score', y='payment_inc_ratio', style='o', \n",
    "    markerfacecolor='none', markeredgecolor='C0', ax=ax)\n",
    "ax.legend(['paid off', 'default']);\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 25)\n",
    "ax.set_xlabel('borrower_score')\n",
    "ax.set_ylabel('payment_inc_ratio')\n",
    "\n",
    "x0 = 0.575\n",
    "x1a = 0.325; y1b = 9.191\n",
    "y2a = 10.423; x2b = 0.725\n",
    "ax.plot((x0, x0), (0, 25), color='grey')\n",
    "ax.plot((x1a, x1a), (0, 25), color='grey')\n",
    "ax.plot((x0, 1), (y1b, y1b), color='grey')\n",
    "ax.plot((x1a, x0), (y2a, y2a), color='grey')\n",
    "ax.plot((x2b, x2b), (0, y1b), color='grey')\n",
    "\n",
    "labels = [('default', (x1a / 2, 25 / 2)),\n",
    "          ('default', ((x0 + x1a) / 2, (25 + y2a) / 2)),\n",
    "          ('paid off', ((x0 + x1a) / 2, y2a / 2)),\n",
    "          ('paid off', ((1 + x0) / 2, (y1b + 25) / 2)),\n",
    "          ('paid off', ((1 + x2b) / 2, (y1b + 0) / 2)),\n",
    "          ('paid off', ((x0 + x2b) / 2, (y1b + 0) / 2)),\n",
    "         ]\n",
    "for label, (x, y) in labels:\n",
    "    ax.text(x, y, label, bbox={'facecolor':'white'},\n",
    "            verticalalignment='center', horizontalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Homogeneity or Impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyFunction(x):\n",
    "    if x == 0: return 0\n",
    "    return -x * math.log(x, 2) - (1 - x) * math.log(1 - x, 2)\n",
    "\n",
    "def giniFunction(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 0.5, 50)\n",
    "impure = pd.DataFrame({\n",
    "    'x': x,\n",
    "    'Accuracy': 2 * x,\n",
    "    'Gini': [giniFunction(xi) / giniFunction(.5) for xi in x],\n",
    "    'Entropy': [entropyFunction(xi) for xi in x],\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "impure.plot(x='x', y='Accuracy', ax=ax, linestyle='solid')\n",
    "impure.plot(x='x', y='Entropy', ax=ax, linestyle='--')\n",
    "impure.plot(x='x', y='Gini', ax=ax, linestyle=':')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and the Random Forest\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a simple random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['borrower_score', 'payment_inc_ratio']\n",
    "outcome = 'outcome'\n",
    "\n",
    "X = loan3000[predictors]\n",
    "y = loan3000[outcome]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=1, \n",
    "                            oob_score=True)\n",
    "rf.fit(X, y)\n",
    "print(rf.oob_decision_function_)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator = list(range(20, 510, 5))\n",
    "oobScores = []\n",
    "for n in n_estimator:\n",
    "    rfc = RandomForestClassifier(n_estimators=n, \n",
    "                                criterion='entropy', max_depth=5,\n",
    "                                random_state=1, oob_score=True)\n",
    "    rfc.fit(X, y)\n",
    "    oobScores.append(rfc.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'n': n_estimator, \n",
    "    'oobScore': oobScores\n",
    "}).plot(x='n', y='oobScore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HomeWork1\n",
    "#### 1 - Please recreate the above chart using testing dataset which created through train-test spliting\n",
    "#### 2 - Please compare the result between OOB score and test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "loan3000_2=loan3000.copy()\n",
    "loan3000_2['dv'] = [1 if out==\"default\" else 0 for out in loan3000['outcome']]\n",
    "\n",
    "\n",
    "predictors = ['borrower_score', 'payment_inc_ratio']\n",
    "outcome = 'dv'\n",
    "\n",
    "# prepare train-test split\n",
    "X = loan3000_2[predictors]\n",
    "y = loan3000_2[outcome]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "n_estimator = list(range(20, 510, 5))\n",
    "testScores = []\n",
    "\n",
    "for n in n_estimator:\n",
    "    rfc = RandomForestClassifier(n_estimators=n, random_state=1)\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    # predictions\n",
    "    auc=roc_auc_score(y_test, rfc.predict(X_test), average='macro')\n",
    "    testScores.append(auc)\n",
    "    #print(n,auc, sum(y_test), sum(rfc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'n': n_estimator, \n",
    "    'TestAUC': testScores\n",
    "}).plot(x='n', y='TestAUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = X.copy()\n",
    "predictions['prediction'] = rf.predict(X)\n",
    "predictions.head()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "predictions.loc[predictions.prediction=='paid off'].plot(\n",
    "    x='borrower_score', y='payment_inc_ratio', style='.',\n",
    "    markerfacecolor='none', markeredgecolor='C1', ax=ax)\n",
    "predictions.loc[predictions.prediction=='default'].plot(\n",
    "    x='borrower_score', y='payment_inc_ratio', style='o',\n",
    "    markerfacecolor='none', markeredgecolor='C0', ax=ax)\n",
    "ax.legend(['paid off', 'default']);\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 25)\n",
    "ax.set_xlabel('borrower_score')\n",
    "ax.set_ylabel('payment_inc_ratio')\n",
    "\n",
    "plt.title(\"The Predicted Outcomes from RF\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest overfitting can be observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable importance\n",
    "This is different to R. The accuracy decrease is not available out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv(LOAN_DATA_CSV)\n",
    "loan_data = loan_data.drop(columns=['Unnamed: 0', 'status'])\n",
    "loan_data['outcome'] = pd.Categorical(loan_data['outcome'], \n",
    "                                      categories=['paid off', 'default'], \n",
    "                                      ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['loan_amnt', 'term', 'annual_inc', 'dti', \n",
    "              'payment_inc_ratio', 'revol_bal', 'revol_util', \n",
    "              'purpose', 'delinq_2yrs_zero', 'pub_rec_zero', \n",
    "              'open_acc', 'grade', 'emp_length', 'purpose_', \n",
    "              'home_', 'emp_len_', 'borrower_score']\n",
    "outcome = 'outcome'\n",
    "\n",
    "X = pd.get_dummies(loan_data[predictors], drop_first=True)\n",
    "y = loan_data[outcome]\n",
    "\n",
    "rf_all = RandomForestClassifier(n_estimators=200, random_state=1)\n",
    "rf_all.fit(X, y)\n",
    "print(rf_all.fit(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'feature': X.columns, \n",
    "    'importance': rf_all.feature_importances_\n",
    "})\n",
    "df = df.sort_values('importance')\n",
    "\n",
    "ax = df.plot(kind='barh', x='feature', y='importance', \n",
    "             title=\"Feature Importance\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['borrower_score', 'payment_inc_ratio']\n",
    "outcome = 'outcome'\n",
    "\n",
    "X = loan3000[predictors]\n",
    "y = loan3000[outcome]\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic', subsample=.63)\n",
    "print(xgb.fit(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df = X.copy()\n",
    "xgb_df['prediction'] = xgb.predict(X)\n",
    "xgb_df['prob_default'] = xgb.predict_proba(X)[:, 0]\n",
    "print(xgb_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "xgb_df.loc[xgb_df.prediction=='paid off'].plot(\n",
    "    x='borrower_score', y='payment_inc_ratio', style='.', \n",
    "    markerfacecolor='none', markeredgecolor='C1', ax=ax)\n",
    "xgb_df.loc[xgb_df.prediction=='default'].plot(\n",
    "    x='borrower_score', y='payment_inc_ratio', style='o', \n",
    "    markerfacecolor='none', markeredgecolor='C0', ax=ax)\n",
    "ax.legend(['paid off', 'default']);\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 25)\n",
    "ax.set_xlabel('borrower_score')\n",
    "ax.set_ylabel('payment_inc_ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization: Avoiding Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['loan_amnt', 'term', 'annual_inc', 'dti', \n",
    "              'payment_inc_ratio', 'revol_bal', 'revol_util', \n",
    "              'purpose', 'delinq_2yrs_zero', 'pub_rec_zero', \n",
    "              'open_acc', 'grade', 'emp_length', 'purpose_', \n",
    "              'home_', 'emp_len_', 'borrower_score']\n",
    "outcome = 'outcome'\n",
    "\n",
    "X = pd.get_dummies(loan_data[predictors], drop_first=True)\n",
    "y = pd.Series([1 if o == 'default' else 0 for o in loan_data[outcome]])\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=10000)\n",
    "\n",
    "xgb_default = XGBClassifier(objective='binary:logistic', n_estimators=250, max_depth=6,\n",
    "                            reg_lambda=0, learning_rate=0.3, subsample=1)\n",
    "xgb_default.fit(train_X, train_y)\n",
    "\n",
    "xgb_penalty = XGBClassifier(objective='binary:logistic', n_estimators=250, max_depth=6,\n",
    "                            reg_lambda=1000, learning_rate=0.1, subsample=0.63, colsample_bytree=0.7)\n",
    "print(xgb_penalty.fit(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_default = xgb_default.predict_proba(train_X)[:, 1]\n",
    "error_default = abs(train_y - pred_default) > 0.5\n",
    "print('default (train): ', np.mean(error_default))\n",
    "\n",
    "pred_default = xgb_default.predict_proba(valid_X)[:, 1]\n",
    "error_default = abs(valid_y - pred_default) > 0.5\n",
    "print('default: ', np.mean(error_default))\n",
    "\n",
    "pred_penalty = xgb_penalty.predict_proba(valid_X)[:, 1]\n",
    "error_penalty = abs(valid_y - pred_penalty) > 0.5\n",
    "print('penalty: ', np.mean(error_penalty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for ntree_limit in range(1, 250):\n",
    "    train_default = xgb_default.predict_proba(train_X, ntree_limit=ntree_limit)[:, 1]\n",
    "    train_penalty = xgb_penalty.predict_proba(train_X, ntree_limit=ntree_limit)[:, 1]\n",
    "    pred_default = xgb_default.predict_proba(valid_X, ntree_limit=ntree_limit)[:, 1]\n",
    "    pred_penalty = xgb_penalty.predict_proba(valid_X, ntree_limit=ntree_limit)[:, 1]\n",
    "    results.append({\n",
    "        'iterations': ntree_limit,\n",
    "        'default train': np.mean(abs(train_y - train_default) > 0.5),\n",
    "        'penalty train': np.mean(abs(train_y - train_penalty) > 0.5),\n",
    "        'default test': np.mean(abs(valid_y - pred_default) > 0.5),\n",
    "        'penalty test': np.mean(abs(valid_y - pred_penalty) > 0.5),\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = results.plot(x='iterations', y='default test')\n",
    "results.plot(x='iterations', y='penalty test', ax=ax)\n",
    "results.plot(x='iterations', y='default train', ax=ax)\n",
    "results.plot(x='iterations', y='penalty train', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small scale grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(5), size=len(X), replace=True)\n",
    "error = []\n",
    "for eta, max_depth in product([0.1, 0.5, 0.9], [3, 6, 9]):\n",
    "    xgb = XGBClassifier(objective='binary:logistic', n_estimators=100, \n",
    "                        max_depth=max_depth, learning_rate=eta)\n",
    "    cv_error = []\n",
    "    for k in range(5):\n",
    "        fold_idx = idx == k\n",
    "        train_X = X.loc[~fold_idx]; train_y = y[~fold_idx]\n",
    "        valid_X = X.loc[fold_idx]; valid_y = y[fold_idx]\n",
    "\n",
    "        xgb.fit(train_X, train_y)\n",
    "        pred = xgb.predict_proba(valid_X)[:, 1]\n",
    "        cv_error.append(np.mean(abs(valid_y - pred) > 0.5))\n",
    "    error.append({\n",
    "        'eta': eta,\n",
    "        'max_depth': max_depth,\n",
    "        'avg_error': np.mean(cv_error)\n",
    "    })\n",
    "    print(error[-1])\n",
    "errors = pd.DataFrame(error)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errors.pivot_table(index='eta', columns='max_depth', values='avg_error') * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## homework2: Could you extend the gridserch to three or more parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
